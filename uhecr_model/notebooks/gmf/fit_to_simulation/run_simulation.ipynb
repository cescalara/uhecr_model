{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Comparison of arrival direction and joint models\n",
    "\n",
    "In order to verify the model is working, we fit simulations made under the assumptions of the model. We also compare the differences between a model for only the UHECR arrival directions and one for both the UHECR arrival directions and energies.\n",
    "<br>\n",
    "<br>\n",
    "*This code is used to produce the data shown in Figures 6, 7 and 8 (left panel) in Capel & Mortlock (2019).*  \n",
    "*See the separate notebook in this directory for the actual plotting of figures.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "from fancy import Data, Model, Analysis\n",
    "from fancy.interfaces.stan import get_simulation_input"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:34:26.049021Z",
     "start_time": "2019-02-01T13:34:23.678075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "'''Setting up'''\n",
    "\n",
    "# Define location of Stan files\n",
    "stan_path = '../../../stan/'\n",
    "\n",
    "# Define file containing source catalogue information\n",
    "source_file = '../../../data/sourcedata.h5'\n",
    "\n",
    "# make output directory if it doesnt exist\n",
    "if not os.path.isdir(\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "\n",
    "# source_types = [\"SBG_23\", \"2FHL_250Mpc\", \"swift_BAT_213\"]\n",
    "source_types = [\"2FHL_250Mpc\"]\n",
    "\n",
    "# detector_types = [\"auger2010\", \"auger2014\", \"TA2015\"]\n",
    "# detector_type = \"auger2014\"\n",
    "# detector_types = [\"TA2015\", \"auger2014\"]\n",
    "detector_types = [\"TA2015\"]\n",
    "\n",
    "# set random seed\n",
    "# random_seeds = [19990308, 4968460, 165490]\n",
    "random_seeds = [19990308]\n",
    "# random_seeds = [19990308, 4968460, 165490, 87, 7984165, 168490, 9874651, 980, 546, 7984, 333, 2]\n",
    "# random_seed = 165490849\n",
    "\n",
    "# flag to control showing plots or not\n",
    "show_plot = True\n",
    "\n",
    "ptypes = [\"N\"]\n",
    "\n",
    "tightB_label = \"highspec\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data = Data()\n",
    "data.add_source(source_file, \"2FHL_250Mpc\")\n",
    "\n",
    "print(data.source.name)\n",
    "print(data.source.distance)\n",
    "\n",
    "print(np.argwhere([data.source.name == b'2FHL J1325.6-4301']))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[b'2FHL J0153.5+7113', b'2FHL J0214.9+5149', b'2FHL J0231.0-5755', b'2FHL J0316.6+4120', b'2FHL J0319.8+4131', b'2FHL J0601.9+5317', b'2FHL J0626.9-3528', b'2FHL J1104.4+3812', b'2FHL J1136.5+7009', b'2FHL J1145.0+1935', b'2FHL J1230.8+1225', b'2FHL J1325.6-4301', b'2FHL J1517.7-2421', b'2FHL J1653.9+3945', b'2FHL J1728.2+5013', b'2FHL J2000.1+6508', b'2FHL J2347.1+5142']\n",
      "[ 94.28571377 209.99999451 137.09571745  81.42856881  75.00000032\n",
      " 222.85714746 235.45714361 132.85714069 192.85715052  93.07713913\n",
      "  18.35571336   7.71428558 205.7142875  144.42857355 237.42856724\n",
      " 201.42856453 188.57142755]\n",
      "[]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "'''Create joint simulated dataset'''\n",
    "\n",
    "# Define a Stan simulation to run\n",
    "sim_name = stan_path + 'joint_gmf_model_sim.stan' # simulate all processes\n",
    "# sim_name = stan_path + 'joint_model_sim.stan' # simulate all processes\n",
    "# Define simulation using Model object and compile Stan code if necessary\n",
    "simulation = Model(sim_filename = sim_name, include_paths = stan_path)\n",
    "simulation.compile(reset=False)\n",
    "\n",
    "for detector_type in detector_types:\n",
    "    '''set detector and detector properties'''\n",
    "    if detector_type == \"TA2015\":\n",
    "        from fancy.detector.TA2015 import detector_properties, alpha_T, M, Eth\n",
    "    elif detector_type == \"auger2014\":\n",
    "        from fancy.detector.auger2014 import detector_properties, alpha_T, M, Eth\n",
    "    elif detector_type == \"auger2010\":\n",
    "        from fancy.detector.auger2010 import detector_properties, alpha_T, M, Eth\n",
    "    else:\n",
    "        raise Exception(\"Undefined detector type!\")\n",
    "        \n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0} {1} {2} {3}\".format(source_type, detector_type, ptype, random_seed))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "\n",
    "                # Define a source catalogue and detector exposure\n",
    "                # In the paper we use the SBG catalogue\n",
    "                data = Data()\n",
    "                data.add_source(source_file, source_type)\n",
    "                data.add_detector(detector_properties)\n",
    "\n",
    "                # Plot the sources in Galactic coordinates\n",
    "                # if show_plot:\n",
    "                #     data.show();\n",
    "\n",
    "                # Define associated fraction\n",
    "                f = 0.5 \n",
    "\n",
    "                # Simulation input\n",
    "                # B = 20 # nG\n",
    "                # alpha = 3.0\n",
    "                B = 15\n",
    "                alpha = 6\n",
    "                Eth = Eth   \n",
    "                Eth_sim = 20 # EeV\n",
    "                ptype = ptype  # assume proton\n",
    "\n",
    "                # number of simulated inputs\n",
    "                # changes the background flux linearly\n",
    "                # should choose Nsim such that FT is the same for\n",
    "                # each observatory\n",
    "                # this ensures that L, F0 are the same\n",
    "                # \n",
    "                # for PAO, we saw that FT, detector_type = 0.3601\n",
    "                # FT_PAO = 0.3601   # total, detector_type flux using {1} data with Nsim = 2500, detector_type\n",
    "                # Nsim_expected = FT_PAO / (M / alpha_T)\n",
    "                # Nsim = int(np.round(Nsim_expected))\n",
    "\n",
    "                Nsim = 2500\n",
    "\n",
    "                # check value for Nsim\n",
    "                print(\"Simulated events: {0}\".format(Nsim))\n",
    "\n",
    "\n",
    "                # L in yr^-1, F in km^-2 yr^-1\n",
    "                L, F0 = get_simulation_input(Nsim, f, data.source.distance, M, alpha_T)\n",
    "\n",
    "                # To scale between definition of flux in simulations and fits\n",
    "                flux_scale = (Eth / Eth_sim)**(1 - alpha)\n",
    "\n",
    "                simulation.input(B = B, L = L, F0 = F0,\n",
    "                            alpha = alpha, Eth = Eth, ptype=ptype)\n",
    "\n",
    "                # check luminosity and isotropic flux values\n",
    "                # L ~ O(10^39), F0 ~ 0.18\n",
    "                # same luminosity so only need to check one value\n",
    "                print(\"Simulated Luminosity: {0:.3e}\".format(L[0]))\n",
    "                print(\"Simulated isotropic flux: {0:.3f}\".format(F0))\n",
    "\n",
    "\n",
    "                # What is happening \n",
    "                summary = b'Simulation using the joint model and SBG catalogue' # must be a byte str\n",
    "                    \n",
    "                # Define an Analysis object to bring together Data and Model objects\n",
    "                # sim_analysis = Analysis(data, simulation, analysis_type = 'joint_gmf', \n",
    "                #                     filename = sim_output_file, summary = summary)\n",
    "\n",
    "                sim_analysis = Analysis(data, simulation, analysis_type = 'joint_gmf', \n",
    "                                    filename = sim_output_file, summary = summary)\n",
    "\n",
    "                print(\"Building tables...\")\n",
    "\n",
    "                # Build pre-computed values for the simulation as you go\n",
    "                # So that you can try out different parameters\n",
    "                sim_analysis.build_tables(sim_only = True)\n",
    "\n",
    "                print(\"Running simulation...\")\n",
    "                # Run simulation\n",
    "                sim_analysis.simulate(seed = random_seed, Eth_sim = Eth_sim)\n",
    "\n",
    "                # Save to file \n",
    "                sim_analysis.save()\n",
    "\n",
    "                # print resulting UHECR observed after propagation and Elosses\n",
    "                print(\"Observed simulated UHECRs: {0}\\n\".format(sim_analysis.N))\n",
    "\n",
    "\n",
    "                # print plots if flag is set to true\n",
    "                # if show_plot:\n",
    "                #     sim_analysis.plot(\"arrival_direction\");\n",
    "                    # sim_analysis.plot(\"energy\");"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cached StanModel\n",
      "Current Source: 2FHL_250Mpc TA2015 N 19990308\n",
      "Simulated events: 2500\n",
      "Simulated Luminosity: 5.775e+41\n",
      "Simulated isotropic flux: 0.997\n",
      "Building tables...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Precomputing exposure integral: 100%|██████████| 17/17 [00:01<00:00, 13.18it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Running simulation...\n",
      "Running Stan simulation...\n",
      "Extracting output...\n",
      "Simulating deflections...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Adding UHECR to Map Container: 100%|██████████| 1037/1037 [02:45<00:00,  6.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing truncations due to exposure...\n",
      "Simulating zenith angles...\n",
      "Computing kappa_gmf...\n",
      "Done!\n",
      "Observed simulated UHECRs: 7\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "'''Fit using arrival direction model'''\n",
    "for detector_type in detector_types:\n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0}\".format(source_type))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                arrival_output_file = 'output/arrival_direction_fit_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                # joint_output_file = 'output/joint_fit_{0}_PAO.h5'.format(source_type)\n",
    "\n",
    "                # Define data from simulation\n",
    "                data = Data()\n",
    "                data.from_file(sim_output_file)\n",
    "\n",
    "                # if show_plot:\n",
    "                #     data.show()\n",
    "\n",
    "                # Arrival direction model\n",
    "                model_name = stan_path + 'arrival_direction_model.stan'\n",
    "\n",
    "                # Compile\n",
    "                model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "                model.compile(reset=False)\n",
    "\n",
    "                # Define threshold energy in EeV\n",
    "                model.input(Eth = Eth)\n",
    "\n",
    "                # What is happening \n",
    "                summary = b'Fit of the arrival direction model to the joint simulation' \n",
    "                    \n",
    "                # Define an Analysis object to bring together Data and Model objects\n",
    "                analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                                    filename = arrival_output_file, summary = summary)\n",
    "\n",
    "                # Define location of pre-computed values used in fits \n",
    "                # (see relevant notebook for how to make these files) \n",
    "                # Each catalogue has a file of pre-computed values\n",
    "                analysis.use_tables(table_file)\n",
    "\n",
    "                # Fit the Stan model\n",
    "                fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "                # Save to analysis file\n",
    "                analysis.save()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: 2FHL_250Mpc\n",
      "Using cached StanModel\n",
      "Performing fitting...\n",
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "'''Fit using joint model'''\n",
    "for detector_type in detector_types:\n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0}\".format(source_type))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                # arrival_output_file = 'output/arrival_direction_fit_{0}_{1}_{2}_{3}.h5'.format(source_type, detector_type, random_seed, ptype)\n",
    "                joint_output_file = 'output/joint_fit_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "\n",
    "                # Define data from simulation\n",
    "                data = Data()\n",
    "                data.from_file(sim_output_file)\n",
    "\n",
    "                # create Model and compile \n",
    "                model_name = stan_path + 'joint_model.stan'\n",
    "                model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "                model.compile(reset=False)\n",
    "                model.input(Eth = Eth)\n",
    "\n",
    "                # create Analysis object\n",
    "                summary = b'Fit of the joint model to the joint + gmf simulation' \n",
    "                analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                                    filename = joint_output_file, summary = summary)\n",
    "                analysis.use_tables(table_file)\n",
    "\n",
    "                # Fit the Stan model\n",
    "                fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "                # Save to analysis file\n",
    "                analysis.save()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: 2FHL_250Mpc\n",
      "Using cached StanModel\n",
      "Performing fitting...\n",
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "'''Fit using joint + gmf model'''\n",
    "for detector_type in detector_types:\n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0}\".format(source_type))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                # arrival_output_file = 'output/arrival_direction_fit_{0}_{1}_{2}_{4}.h5'.format(source_type, detector_type, random_seed, ptype)\n",
    "                joint_gmf_output_file = 'output/joint_gmf_fit_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "\n",
    "                # Define data from simulation\n",
    "                data = Data()\n",
    "                data.from_file(sim_output_file)\n",
    "\n",
    "                print(type(data.uhecr.ptype))\n",
    "                print(isinstance(data.uhecr.ptype, bytes))\n",
    "                # print(data.uhecr.ptype.decode('UTF-8'))\n",
    "\n",
    "                # create Model and compile \n",
    "                model_name = stan_path + 'joint_gmf_model.stan'\n",
    "                model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "                model.compile(reset=False)\n",
    "                model.input(Eth = Eth)\n",
    "\n",
    "                # create Analysis object\n",
    "                summary = b'Fit of the joint + gmf model to the joint + gmf simulation' \n",
    "                analysis = Analysis(data, model, analysis_type = 'joint_gmf', \n",
    "                                    filename = joint_gmf_output_file, summary = summary)\n",
    "\n",
    "                # print(analysis.ptype)\n",
    "                analysis.use_tables(table_file)\n",
    "\n",
    "                # Fit the Stan model\n",
    "                fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "                # Save to analysis file\n",
    "                analysis.save()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: 2FHL_250Mpc\n",
      "<class 'str'>\n",
      "False\n",
      "Using cached StanModel\n",
      "Performing fitting...\n",
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "'''Fit using joint + gmf model'''\n",
    "for detector_type in detector_types:\n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0}\".format(source_type))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                # arrival_output_file = 'output/arrival_direction_fit_{0}_{1}_{2}_{4}.h5'.format(source_type, detector_type, random_seed, ptype)\n",
    "                joint_gmf_output_file = 'output/joint_gmf_fit_{0}_{1}_{2}_{3}_{4}_boxB.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "\n",
    "                # Define data from simulation\n",
    "                data = Data()\n",
    "                data.from_file(sim_output_file)\n",
    "\n",
    "                print(type(data.uhecr.ptype))\n",
    "                print(isinstance(data.uhecr.ptype, bytes))\n",
    "                # print(data.uhecr.ptype.decode('UTF-8'))\n",
    "\n",
    "                # create Model and compile \n",
    "                model_name = stan_path + 'joint_gmf_model_boxB.stan'\n",
    "                model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "                model.compile(reset=False)\n",
    "                model.input(Eth = Eth)\n",
    "\n",
    "                # create Analysis object\n",
    "                summary = b'Fit of the joint + gmf model to the joint + gmf simulation' \n",
    "                analysis = Analysis(data, model, analysis_type = 'joint_gmf', \n",
    "                                    filename = joint_gmf_output_file, summary = summary)\n",
    "\n",
    "                # print(analysis.ptype)\n",
    "                analysis.use_tables(table_file)\n",
    "\n",
    "                # Fit the Stan model\n",
    "                fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "                # Save to analysis file\n",
    "                analysis.save()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL model_796421b15dba71ea90c4ceb636896c82 NOW.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: 2FHL_250Mpc\n",
      "<class 'str'>\n",
      "False\n",
      "Performing fitting...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Initialization failed.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/cartopy/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/miniconda3/envs/cartopy/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"stanfit4model_796421b15dba71ea90c4ceb636896c82_6090744230246176669.pyx\", line 373, in stanfit4model_796421b15dba71ea90c4ceb636896c82_6090744230246176669._call_sampler_star\n  File \"stanfit4model_796421b15dba71ea90c4ceb636896c82_6090744230246176669.pyx\", line 406, in stanfit4model_796421b15dba71ea90c4ceb636896c82_6090744230246176669._call_sampler\nRuntimeError: Initialization failed.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-600c72e937f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# Fit the Stan model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m# Save to analysis file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/uhecr_project/fancy/fancy/analysis/analysis.py\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(self, iterations, chains, seed, sample_file, warmup)\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;31m# fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performing fitting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         self.fit = self.model.model.sampling(data=self.fit_input,\n\u001b[0m\u001b[1;32m    968\u001b[0m                                              \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                                              \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cartopy/lib/python3.8/site-packages/pystan/model.py\u001b[0m in \u001b[0;36msampling\u001b[0;34m(self, data, pars, chains, iter, warmup, thin, seed, init, sample_file, diagnostic_file, verbose, algorithm, control, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mcall_sampler_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mcall_sampler_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_sampler_star\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0mret_and_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_sampler_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_sampler_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msmpl\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret_and_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cartopy/lib/python3.8/site-packages/pystan/model.py\u001b[0m in \u001b[0;36m_map_parallel\u001b[0;34m(function, args, n_jobs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mmap_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cartopy/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/cartopy/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Initialization failed."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf12d0ded482eea021fd85ca119abab43edea472cc6bee318acc6114fd9d5bf9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('cartopy': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}