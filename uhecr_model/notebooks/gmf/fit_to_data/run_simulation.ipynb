{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import os\n",
    "from fancy import Data, Model, Analysis"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "'''Setting up'''\n",
    "# Define location of Stan files\n",
    "stan_path = '../../../stan/'\n",
    "\n",
    "# Define file containing source catalogue information\n",
    "source_file = '../../../data/sourcedata.h5'\n",
    "uhecr_file = '../../../data/UHECRdata.h5'\n",
    "\n",
    "# make output directory if it doesnt exist\n",
    "if not os.path.isdir(\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "\n",
    "# source_types = [\"SBG_23\", \"2FHL_250Mpc\", \"swift_BAT_213\"]\n",
    "source_types = [\"SBG_23\"]\n",
    "\n",
    "# detector_types = [\"auger2010\", \"auger2014\", \"TA2015\"]\n",
    "# detector_type = \"auger2014\"\n",
    "detector_type = \"TA2015\"\n",
    "\n",
    "# set random seed\n",
    "random_seed = 19990308\n",
    "\n",
    "# flag to control showing plots or not\n",
    "show_plot = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "'''set detector and detector properties'''\n",
    "if detector_type == \"TA2015\":\n",
    "    from fancy.detector.TA2015 import detector_properties, alpha_T, M, Eth\n",
    "elif detector_type == \"auger2014\":\n",
    "    from fancy.detector.auger2014 import detector_properties, alpha_T, M, Eth\n",
    "elif detector_type == \"auger2010\":\n",
    "    from fancy.detector.auger2010 import detector_properties, alpha_T, M, Eth\n",
    "else:\n",
    "    raise Exception(\"Undefined detector type!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "'''Fit arrival model'''\n",
    "for source_type in source_types:\n",
    "    # table file\n",
    "    table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)    \n",
    "    # define output files\n",
    "    arrival_output_file = 'output/arrival_fit_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "\n",
    "    # construct Dataset\n",
    "    data = Data()\n",
    "    data.add_source(source_file, source_type)\n",
    "    data.add_uhecr(uhecr_file, detector_type, ptype=\"He\")\n",
    "    data.add_detector(detector_properties)\n",
    "\n",
    "\n",
    "    # data.show();\n",
    "\n",
    "    # construct arrival model obejct\n",
    "    arrival_model = stan_path + 'arrival_direction_model.stan'\n",
    "    model = Model(model_filename = arrival_model, include_paths = stan_path)\n",
    "    model.compile()\n",
    "    model.input(Eth = Eth) # EeV\n",
    "\n",
    "    # What is happening \n",
    "    # summary = b'Fit of the joint model to the Auger data' \n",
    "    summary = b'Fit of the arrival direction model to data' \n",
    "        \n",
    "    # Define an Analysis object to bring together Data and Model objects\n",
    "    analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                        filename = arrival_output_file, summary = summary)\n",
    "\n",
    "    # Define location of pre-computed values used in fits \n",
    "    # (see relevant notebook for how to make these files) \n",
    "    # Each catalogue has a file of pre-computed values\n",
    "    analysis.use_tables(table_file)\n",
    "\n",
    "    # Fit the Stan model\n",
    "    fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "    # Save to analysis file\n",
    "    analysis.save()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cached StanModel\n",
      "Performing fitting...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:pystan:1 of 4000 iterations ended with a divergence (0.025 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "'''Fit joint model'''\n",
    "for source_type in source_types:\n",
    "    # table file\n",
    "    table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)    \n",
    "    # define output files\n",
    "    joint_output_file = 'output/joint_fit_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "\n",
    "    # construct Dataset\n",
    "    data = Data()\n",
    "    data.add_source(source_file, source_type)\n",
    "    data.add_uhecr(uhecr_file, detector_type)\n",
    "    data.add_detector(detector_properties)\n",
    "\n",
    "    # if show_plot:\n",
    "    #     data.show()\n",
    "\n",
    "    joint_model = stan_path + 'joint_model_tightB.stan'\n",
    "    model = Model(model_filename = joint_model, include_paths = stan_path)\n",
    "    model.compile()\n",
    "    model.input(Eth = Eth) # EeV\n",
    "\n",
    "    # What is happening \n",
    "    # summary = b'Fit of the joint model to the Auger data' \n",
    "    summary = b'Fit of the joint model to data' \n",
    "        \n",
    "    # Define an Analysis object to bring together Data and Model objects\n",
    "    analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                        filename = joint_output_file, summary = summary)\n",
    "\n",
    "    # Define location of pre-computed values used in fits \n",
    "    # (see relevant notebook for how to make these files) \n",
    "    # Each catalogue has a file of pre-computed values\n",
    "    analysis.use_tables(table_file)\n",
    "\n",
    "    # Fit the Stan model\n",
    "    fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "    # Save to analysis file\n",
    "    analysis.save()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cached StanModel\n",
      "Performing fitting...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "'''Fit joint + gmf model'''\n",
    "\n",
    "ptype = \"Fe\"\n",
    "for source_type in source_types:\n",
    "    # table file\n",
    "    table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)    \n",
    "    # define output files\n",
    "    joint_output_file = 'output/joint_gmf_fit_{0}_{1}_{2}.h5'.format(source_type, detector_type, ptype)\n",
    "\n",
    "    # construct Dataset\n",
    "    data = Data()\n",
    "    data.add_source(source_file, source_type)\n",
    "    data.add_uhecr(uhecr_file, detector_type, ptype=ptype)\n",
    "    data.add_detector(detector_properties)\n",
    "\n",
    "    # if show_plot:\n",
    "    #     data.show()\n",
    "\n",
    "    joint_model = stan_path + 'joint_gmf_model_tightB.stan'\n",
    "    model = Model(model_filename = joint_model, include_paths = stan_path)\n",
    "    model.compile()\n",
    "    model.input(Eth = Eth) # EeV\n",
    "\n",
    "    # What is happening \n",
    "    # summary = b'Fit of the joint model to the Auger data' \n",
    "    summary = b'Fit of the joint model to data' \n",
    "        \n",
    "    # Define an Analysis object to bring together Data and Model objects\n",
    "    analysis = Analysis(data, model, analysis_type = 'joint_gmf', \n",
    "                        filename = joint_output_file, summary = summary)\n",
    "\n",
    "    # Define location of pre-computed values used in fits \n",
    "    # (see relevant notebook for how to make these files) \n",
    "    # Each catalogue has a file of pre-computed values\n",
    "    analysis.use_tables(table_file)\n",
    "\n",
    "    # Fit the Stan model\n",
    "    fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "    # Save to analysis file\n",
    "    analysis.save()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cached StanModel\n",
      "Performing fitting...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:3 of 4000 iterations ended with a divergence (0.075 %).\n",
      "WARNING:pystan:Try running with adapt_delta larger than 0.8 to remove the divergences.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('cartopy': conda)"
  },
  "interpreter": {
   "hash": "cf12d0ded482eea021fd85ca119abab43edea472cc6bee318acc6114fd9d5bf9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}