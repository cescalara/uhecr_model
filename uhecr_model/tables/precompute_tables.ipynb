{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Precomputing values for use in fits of Stan models\n",
    "\n",
    "Because of the way Stan works, it is necessary to compute some values in advance which can then be passed into the fit an interpolated over. The precomputed values will be different for different sets of source distances, and therefore different catalogues. \n",
    "\n",
    "Here we show how to compute the values for the SBG catalogue, but it is exactly the same for all cases, just changing the input label.\n",
    "\n",
    "For ease, all the precomputed table files used are provided for use in this repository."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from fancy import Data, Model, Analysis\n",
    "\n",
    "# Define file containing catalogue information\n",
    "source_file = '../data/sourcedata.h5'\n",
    "\n",
    "# this is assuming that detector properties == data given in UHECR data\n",
    "# which is generally wrong, but this assumption is used for now\n",
    "uhecr_file = '../data/UHECRdata.h5'\n",
    "\n",
    "# Path to Stan files\n",
    "stan_path = '../stan/'\n",
    "\n",
    "# source_types = [\"SBG_23\", \"2FHL_250Mpc\", \"swift_BAT_213\"]\n",
    "source_types = [\"SBG_23\"]\n",
    "\n",
    "# type of detector / UHECR dataset\n",
    "detector_type = \"TA2015\""
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:29:36.686912Z",
     "start_time": "2019-02-01T13:29:34.322950Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# change detector property imports based on detector type string\n",
    "if detector_type == \"TA2015\":\n",
    "    from fancy.detector.TA2015 import detector_properties, Eth\n",
    "elif detector_type == \"auger2014\":\n",
    "    from fancy.detector.auger2014 import detector_properties, Eth\n",
    "elif detector_type == \"auger2010\":\n",
    "    from fancy.detector.auger2010 import detector_properties, Eth\n",
    "else:\n",
    "    raise Exception(\"Undefined detector type!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "'''Precompute exposure integral table, energy grid, and kappa_d values'''\n",
    "\n",
    "for source_type in source_types:\n",
    "    print(\"Current Source: {0}\".format(source_type))\n",
    "\n",
    "    # File in which to store precomputation\n",
    "    # create new files with TA label\n",
    "    table_file = \"tables_{0}_{1}.h5\".format(source_type, detector_type)\n",
    "\n",
    "    data = Data()\n",
    "    data.add_source(source_file, source_type) \n",
    "    data.add_uhecr(uhecr_file, detector_type) \n",
    "    data.add_detector(detector_properties)  # KW: add detector information\n",
    "\n",
    "    model_name = 'joint_model.stan'\n",
    "    model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "    model.input(Eth = Eth) # EeV\n",
    "\n",
    "    summary = b'Precomputation for tables'\n",
    "    analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                        filename = table_file, summary = summary)\n",
    "\n",
    "    print(\"Evaluating Exposure Integral...\")\n",
    "    analysis.build_tables(fit_only = True)\n",
    "    analysis.tables.save(table_file)\n",
    "\n",
    "    print(\"Evaluating Arrival Energies...\")\n",
    "    analysis.build_energy_table(table_file = table_file)\n",
    "\n",
    "    print(\"Evaluating kappa_d for each composition...\")\n",
    "    analysis.build_kappad(table_file=table_file)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: SBG_23\n",
      "Evaluating Exposure Integral...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Precomputing exposure integral: 100%|██████████| 23/23 [01:44<00:00,  4.55s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Evaluating Arrival Energies...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Precomputing energy grids: 100%|██████████| 23/23 [00:54<00:00,  2.38s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating kappa_d for each composition...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Precomputing kappa_d for each composition: 100%|██████████| 9/9 [00:35<00:00,  3.95s/it]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# check if the table is constructed correctly:\n",
    "\n",
    "for source_type in source_types:\n",
    "    print(\"Current Source: {0}\".format(source_type))\n",
    "\n",
    "    # File in which to store precomputation\n",
    "    # create new files with TA label\n",
    "    table_file = \"tables_{0}_{1}.h5\".format(source_type, detector_type)\n",
    "\n",
    "    with h5py.File(table_file, \"r\") as f:\n",
    "        print(f.keys())\n",
    "\n",
    "        print(\"Exposure integral keys:\")\n",
    "        print(f[\"main\"].keys())   # main exposure integral table\n",
    "\n",
    "        print(\"Energy Grid keys:\")\n",
    "        print(f[\"energy\"].keys())\n",
    "\n",
    "        print(\"kappa_d keys:\")\n",
    "        print(f[\"kappa_d\"].keys())\n",
    "        print(f[\"kappa_d\"][\"p\"].keys())  # take proton for example\n",
    "\n",
    "        # print(f[\"kappa_d\"][\"p\"][\"omega_gal\"][()].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: SBG_23\n",
      "<KeysViewHDF5 ['energy', 'kappa_d', 'main', 'params', 'simulation', 'varpi']>\n",
      "Exposure integral keys:\n",
      "<KeysViewHDF5 ['kappa', 'table']>\n",
      "Energy Grid keys:\n",
      "<KeysViewHDF5 ['E_grid', 'Earr_grid']>\n",
      "kappa_d keys:\n",
      "<KeysViewHDF5 ['C', 'Fe', 'H', 'He', 'Li', 'N', 'O', 'Si', 'p']>\n",
      "<KeysViewHDF5 ['kappa_d', 'omega_gal', 'omega_rand', 'omega_true']>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}