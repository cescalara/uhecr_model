{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precomputing values for use in fits of Stan models\n",
    "\n",
    "Because of the way Stan works, it is necessary to compute some values in advance which can then be passed into the fit an interpolated over. The precomputed values will be different for different sets of source distances, and therefore different catalogues. \n",
    "\n",
    "Here we show how to compute the values for the SBG catalogue, but it is exactly the same for all cases, just changing the input label.\n",
    "\n",
    "For ease, all the precomputed table files used are provided for use in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:29:36.686912Z",
     "start_time": "2019-02-01T13:29:34.322950Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "from fancy import Data, Model, Analysis\n",
    "# from fancy.detector.auger2014 import detector_properties\n",
    "from fancy.detector.TA2015 import detector_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:29:50.021325Z",
     "start_time": "2019-02-01T13:29:50.016833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define file containing catalogue information\n",
    "source_file = '../data/sourcedata.h5'\n",
    "\n",
    "# Path to Stan files\n",
    "stan_path = '../stan/'\n",
    "\n",
    "# make output directory if it doesnt exist\n",
    "if not os.path.isdir(\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "\n",
    "# File in which to store precomputation\n",
    "# create new files with TA label\n",
    "# table_file = 'output/precomputation_storage.h5'\n",
    "# table_file = 'output/precomputation_storage_TA.h5'\n",
    "table_file = \"../data/table_SBG_23_TA.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:29:50.950367Z",
     "start_time": "2019-02-01T13:29:50.937089Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2FHL_250Mpc\nSBG_23\nswift_BAT_213\n"
     ]
    }
   ],
   "source": [
    "# What sources do we have info on?\n",
    "with h5py.File(source_file, 'r') as f:\n",
    "    for key in f:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data, model and analysis\n",
    "\n",
    "The precomputed values depend on the source locations and the detector parameters. We also need to define a model in order to pass $E_\\rm{th}$ into the energy interpolation tables.\n",
    "\n",
    "The Analysis object brings together data and model inputs and provides an interface to do the precomputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:29:56.673003Z",
     "start_time": "2019-02-01T13:29:56.497105Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Data()\n",
    "data.add_source(source_file, 'SBG_23') \n",
    "data.source.select_sources([0, 1]) # just select 2 sources to speed up demo\n",
    "data.add_detector(detector_properties)  # KW: add detector information\n",
    "\n",
    "model_name = 'joint_model.stan'\n",
    "model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "# model.input(Eth = 52) # EeV\n",
    "model.input(Eth = 57) # EeV\n",
    "\n",
    "# precomp_output = 'output/testing_precomputation.h5'\n",
    "precomp_output = 'output/testing_precomputation_TA.h5'\n",
    "summary = b'Demonstration of precomputation.' \n",
    "analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                    filename = precomp_output, summary = summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "data.add_source(source_file, 'SBG_23') \n",
    "# data.source.select_sources([0, 1]) # just select 2 sources to speed up demo\n",
    "data.add_detector(detector_properties)  # KW: add detector information\n",
    "\n",
    "model_name = 'joint_model.stan'\n",
    "model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "# model.input(Eth = 52) # EeV\n",
    "model.input(Eth = 57) # EeV\n",
    "\n",
    "# precomp_output = 'output/testing_precomputation.h5'\n",
    "# precomp_output = 'output/testing_precomputation_TA.h5'\n",
    "# summary = b'Demonstration of precomputation.' \n",
    "summary = b'Precomputation for SBG catalogue with TA observatory'\n",
    "analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                    filename = table_file, summary = summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposure integral precomputation\n",
    "See Equation A6 in Capel & Mortlock (2019). Interpolated over to calculate $\\bar{N}$ in the fit when $\\kappa$ is unknown a priori.\n",
    "\n",
    "$$\n",
    "\\epsilon_k = \\int \\rm{d} \\omega \\ p(\\omega | \\varpi_k, \\kappa) \\epsilon(\\omega)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:32:51.004206Z",
     "start_time": "2019-02-01T13:29:59.716374Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Precomputing exposure integral:   4%|▍         | 1/23 [01:24<30:49, 84.09s/it]\n",
      "Precomputing exposure integral:   9%|▊         | 2/23 [02:19<26:24, 75.47s/it]\n",
      "Precomputing exposure integral:  13%|█▎        | 3/23 [03:11<22:51, 68.57s/it]\n",
      "Precomputing exposure integral:  17%|█▋        | 4/23 [04:11<20:52, 65.91s/it]\n",
      "Precomputing exposure integral:  22%|██▏       | 5/23 [05:31<21:00, 70.04s/it]\n",
      "Precomputing exposure integral:  26%|██▌       | 6/23 [06:27<18:41, 65.99s/it]\n",
      "Precomputing exposure integral:  30%|███       | 7/23 [07:42<18:15, 68.47s/it]\n",
      "Precomputing exposure integral:  35%|███▍      | 8/23 [08:45<16:42, 66.83s/it]\n",
      "Precomputing exposure integral:  39%|███▉      | 9/23 [10:07<16:40, 71.44s/it]\n",
      "Precomputing exposure integral:  43%|████▎     | 10/23 [11:29<16:10, 74.65s/it]\n",
      "Precomputing exposure integral:  48%|████▊     | 11/23 [12:41<14:45, 73.82s/it]\n",
      "Precomputing exposure integral:  52%|█████▏    | 12/23 [13:46<13:02, 71.12s/it]\n",
      "Precomputing exposure integral:  57%|█████▋    | 13/23 [14:48<11:23, 68.34s/it]\n",
      "Precomputing exposure integral:  61%|██████    | 14/23 [15:50<10:00, 66.72s/it]\n",
      "Precomputing exposure integral:  65%|██████▌   | 15/23 [17:07<09:16, 69.53s/it]\n",
      "Precomputing exposure integral:  70%|██████▉   | 16/23 [17:58<07:28, 64.09s/it]\n",
      "Precomputing exposure integral:  74%|███████▍  | 17/23 [19:00<06:20, 63.37s/it]\n",
      "Precomputing exposure integral:  78%|███████▊  | 18/23 [20:16<05:37, 67.41s/it]\n",
      "Precomputing exposure integral:  83%|████████▎ | 19/23 [21:23<04:28, 67.07s/it]\n",
      "Precomputing exposure integral:  87%|████████▋ | 20/23 [22:25<03:16, 65.54s/it]\n",
      "Precomputing exposure integral:  91%|█████████▏| 21/23 [23:37<02:14, 67.46s/it]\n",
      "Precomputing exposure integral:  96%|█████████▌| 22/23 [24:55<01:10, 70.66s/it]\n",
      "Precomputing exposure integral: 100%|██████████| 23/23 [25:56<00:00, 67.70s/it]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis.build_tables(fit_only = True)\n",
    "analysis.tables.save(table_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy interpolation\n",
    "Used to speed up fits, can solve the continuous energy loss DE, but can also interpolate over precomputed values to get $E$ given $\\tilde{E}$ for a given $D$ and vice versa.\n",
    "\n",
    "Speed up for a typical fit is from ~hours to ~minutes. I spent a considerable amount of time verifying the results are consistentent between the two methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:33:23.879993Z",
     "start_time": "2019-02-01T13:32:51.006576Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Precomputing energy grids: 100%|██████████| 23/23 [08:19<00:00, 21.70s/it]\n"
     ]
    }
   ],
   "source": [
    "analysis.build_energy_table(table_file = table_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "569d6b7e9215e11aba41c6454007e5c1b78bad7df09dab765d8cf00362c40f03"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}